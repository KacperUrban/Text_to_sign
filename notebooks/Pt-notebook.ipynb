{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from config import DATA_DIR, MODEL_DIR, TOKENIZER_DIR, BASE_DIR\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "import evaluate\n",
    "from custom_utils.custom_pytorch_utils import TranslationDataset, collate_fn, evaluate_model_on_bleu\n",
    "\n",
    "print(load_dotenv(dotenv_path=BASE_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_DIR)\n",
    "print(device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianDecoder(\n",
       "  (embed_tokens): Embedding(63430, 512, padding_idx=63429)\n",
       "  (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x MarianDecoderLayer(\n",
       "      (self_attn): MarianAttention(\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (activation_fn): SiLU()\n",
       "      (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder_attn): MarianAttention(\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze encoder \n",
    "for params in model.model.encoder.layers.parameters():\n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(63430, 512, padding_idx=63429)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(63430, 512, padding_idx=63429)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(63430, 512, padding_idx=63429)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=63430, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 2)\n",
      "(182, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>mig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jaki ma Pan numer domu?</td>\n",
       "      <td>Jaki twój dom numer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czy ma Pani krewnych?</td>\n",
       "      <td>Ty krewni masz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jak nazywa się prezydent polski?</td>\n",
       "      <td>Prezydent polska nazwisko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jakie Pani ma obywatelstwo?</td>\n",
       "      <td>Ty obywatelstwo jakie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gdzie mieszkasz?</td>\n",
       "      <td>Ty mieszkać gdzie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pl                        mig\n",
       "0           Jaki ma Pan numer domu?        Jaki twój dom numer\n",
       "1             Czy ma Pani krewnych?             Ty krewni masz\n",
       "2  Jak nazywa się prezydent polski?  Prezydent polska nazwisko\n",
       "3       Jakie Pani ma obywatelstwo?      Ty obywatelstwo jakie\n",
       "4                  Gdzie mieszkasz?          Ty mieszkać gdzie"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR + \"/final_data/all_data.csv\")\n",
    "train_indices = data.sample(frac=0.85, random_state=42).index\n",
    "train_data = data.iloc[train_indices].reset_index(drop=True)\n",
    "valid_data = data.drop(train_indices).reset_index(drop=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  322,    26,    18,    78,    25,  5898, 17983,   788,     2,     0,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  230,  5986,   151,    54,  2227,    17,   581,    25,  2160,     9,\n",
       "           7688,  1549, 22251,    10, 10260,     2,     0],\n",
       "         [  926,  5171,  1117,  7866,   100,  3567,     7,     0, 63429, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [ 3049,   140,  2320,  2601, 14288, 18334,     7,     0, 63429, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [ 1123,   538, 11413, 20930,   969,    18,   127,     2,     0, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  362,  2320,    45,    88,   389,  2948,   398,     7,     0, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  926,  2320, 17579,  7959,  1810,     7,     0, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [ 3939,   456,   148,  3412,    17,    26,   606,  5551,   550, 13677,\n",
       "              2,     0, 63429, 63429, 63429, 63429, 63429]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]),\n",
       " 'labels': tensor([[ 6714, 17983,   343,   307,    26,  4998,    80,     0, 63429, 63429,\n",
       "          63429],\n",
       "         [  230,  5986,    15,  2313,   151,   307,    10,    15, 17525,   203,\n",
       "              0],\n",
       "         [  834,  7866,   100,  3567, 15057,   535,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [ 2320,  6166,  2601,  1852,     0, 63429, 63429, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [ 1123, 20930,   969,    18,   127, 17794,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  811,    88,   389,  1172,    80,     0, 63429, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  811,  7959,  1810, 17579,    55,   535,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  322, 13677,    19,  5551,  7879,  2237,  3472,   357,    96,     0,\n",
       "          63429]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = TranslationDataset(valid_data.pl, valid_data.mig, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:24<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 3.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:25<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.8305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:25<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:24<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with neptune.init_run() as run:\n",
    "    lr = 5e-5\n",
    "    num_epochs = 5\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    run[\"hyperparameters/learning_rate\"] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    run[\"hyperparameters/optimizer\"] = \"Adam\"\n",
    "    run[\"hyperparameters/betas\"] = stringify_unsupported(optimizer.state_dict()['param_groups'][0]['betas'])\n",
    "    run[\"hyperparameters/eps\"] = optimizer.state_dict()['param_groups'][0]['eps']\n",
    "    run[\"datasets/train\"].track_files(\"data/final_data/all_data.csv\")\n",
    "    run[\"hyperparameters/num_epochs\"] = num_epochs\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_all = 0\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_all += loss.item()\n",
    "        run[\"train/loss\"].append(np.round(loss_all / len(train_dataloader), 4))\n",
    "        print(f\"Epoch: {epoch + 1}, loss: {np.round(loss_all / len(train_dataloader), 4)}\")\n",
    "        \n",
    "    run[\"score/final_loss\"] = np.round(loss_all / len(train_dataloader), 4)\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    bleu_score = evaluate_model_on_bleu(model, valid_dataloader, tokenizer, bleu_metric, device, None)\n",
    "    run[\"metrics/BLEU\"] = bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.659\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU: {bleu_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
