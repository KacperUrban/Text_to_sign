{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "from datasets import load_metric\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"model/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/tokenizer/\")\n",
    "print(device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\urbii\\AppData\\Local\\Temp\\ipykernel_23404\\1174947439.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"bleu\", trust_remote_code=True)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\urbii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\urbii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\urbii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bleu_metric = load_metric(\"bleu\", trust_remote_code=True)\n",
    "meteor_metric = load_metric(\"meteor\", trust_remote_code=True)\n",
    "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 2)\n",
      "(182, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>mig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Czy Pan umie czytaÄ‡?</td>\n",
       "      <td>Pan czytaÄ‡ umieÄ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czy Pan jest gÅ‚uchy?</td>\n",
       "      <td>Pan gÅ‚uchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To jest numer pogotowia ratunkowego 999.</td>\n",
       "      <td>Pogotowie ratunkowe telefon numer 999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nie umiem wypeÅ‚niÄ‡ wniosku.</td>\n",
       "      <td>Ja nie rozumieÄ‡ co pisac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ja zÅ‚amaÅ‚em rÄ™kÄ™ na ulicy.</td>\n",
       "      <td>Ja rÄ™ka ulica zÅ‚amaÄ‡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         pl  \\\n",
       "0                      Czy Pan umie czytaÄ‡?   \n",
       "1                      Czy Pan jest gÅ‚uchy?   \n",
       "2  To jest numer pogotowia ratunkowego 999.   \n",
       "3               Nie umiem wypeÅ‚niÄ‡ wniosku.   \n",
       "4                Ja zÅ‚amaÅ‚em rÄ™kÄ™ na ulicy.   \n",
       "\n",
       "                                     mig  \n",
       "0                       Pan czytaÄ‡ umieÄ‡  \n",
       "1                             Pan gÅ‚uchy  \n",
       "2  Pogotowie ratunkowe telefon numer 999  \n",
       "3               Ja nie rozumieÄ‡ co pisac  \n",
       "4                   Ja rÄ™ka ulica zÅ‚amaÄ‡  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/All_data.csv\")\n",
    "train_indices = data.sample(frac=0.85).index\n",
    "train_data = data.loc[train_indices].reset_index(drop=True)\n",
    "valid_data = data.drop(train_indices).reset_index(drop=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, input_texts, target_texts, tokenizer):\n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.input_texts[idx], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        targets = self.tokenizer(self.target_texts[idx], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        return {**inputs, \"labels\": targets[\"input_ids\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  700,    22,  5024,  2601,  3327,    19,     2,     0, 63429, 63429,\n",
       "          63429],\n",
       "         [  114,  1247,    85,   432,  5496,     2,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  178,   421,  3449,    23,    45,    26,  4054,    95,     2,     0,\n",
       "          63429],\n",
       "         [   50,  4998,    25, 17012,  2422,     2,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  362,   606,  7549,  1450,   111,   466,   461,  6252,    61,     7,\n",
       "              0],\n",
       "         [   12,   243,  2320,    51,  5040,     7,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  700,   748,  7959,  7225,  4425,    63,     2,     0, 63429, 63429,\n",
       "          63429],\n",
       "         [  926,  5171, 24754,  3870,    19,     7,     0, 63429, 63429, 63429,\n",
       "          63429]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]),\n",
       " 'labels': tensor([[  811,  2601,  3327,    19,    22,  5024,  1291,     0],\n",
       "         [  811,   432,  5496,   203,     0, 63429, 63429, 63429],\n",
       "         [ 1217,  3449,    19,    26,  4054,    95,     0, 63429],\n",
       "         [   50, 17805,     5,     0, 63429, 63429, 63429, 63429],\n",
       "         [  322,    51,   461,  6252,    19,   485,     0, 63429],\n",
       "         [  811,    51,  5040,    80,  2010,     0, 63429, 63429],\n",
       "         [   62,  1393,  1436,  4425,   344,   748,  6769,     0],\n",
       "         [  840,  2466,    99,    19, 15057,   535,     0, 63429]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'].squeeze() for item in batch]\n",
    "    attention_mask = [item['attention_mask'].squeeze() for item in batch]\n",
    "    labels = [item['labels'].squeeze() for item in batch]\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "train_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_metrics(model, dataloader, tokenizer, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model.generate(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "            predictions = [tokenizer.decode(g, skip_special_tokens=True) for g in outputs]\n",
    "            references = [tokenizer.decode(g, skip_special_tokens=True) for g in batch[\"labels\"]]\n",
    "\n",
    "            all_preds.extend(predictions)\n",
    "            all_labels.extend(references)\n",
    "\n",
    "    # Tokenize predictions and references\n",
    "    all_preds_tokenized = [pred.split() for pred in all_preds]\n",
    "    all_labels_tokenized = [[label.split()] for label in all_labels]\n",
    "    \n",
    "\n",
    "    # Compute metrics\n",
    "    bleu_score = np.round(bleu_metric.compute(predictions=all_preds_tokenized, references=all_labels_tokenized)['bleu'], 3)\n",
    "    meteor_score = np.round(meteor_metric.compute(predictions=all_preds, references=all_labels)['meteor'], 3)\n",
    "    rouge_score = np.round(rouge_metric.compute(predictions=all_preds, references=all_labels)[\"rougeL\"].mid.fmeasure, 3)\n",
    "\n",
    "    return bleu_score, meteor_score, rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:42<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.4312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:40<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:41<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:40<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.4214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:40<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.3195\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 2 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] All 2 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-33/metadata\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(tags=\"test run\")\n",
    "lr = 5e-5\n",
    "num_epochs = 5\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "run[\"hyperparameters/learning_rate\"] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "run[\"hyperparameters/optimizer\"] = \"Adam\"\n",
    "run[\"hyperparameters/betas\"] = stringify_unsupported(optimizer.state_dict()['param_groups'][0]['betas'])\n",
    "run[\"hyperparameters/eps\"] = optimizer.state_dict()['param_groups'][0]['eps']\n",
    "run[\"hyperparameters/weight_decay\"] = optimizer.state_dict()['param_groups'][0]['weight_decay']\n",
    "run[\"datasets/train\"].track_files(\"data/All_data.csv\")\n",
    "run[\"hyperparameters/num_epochs\"] = num_epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    loss_all = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_all += loss.item()\n",
    "    run[\"train/loss\"].append(np.round(loss_all / len(train_dataloader), 4))\n",
    "    print(f\"Epoch: {epoch + 1}, loss: {np.round(loss_all / len(train_dataloader), 4)}\")\n",
    "\n",
    "    #bleu_score, meteor_score, rouge_score = evaluate_model_on_metrics(model, valid_dataloader, tokenizer, device)\n",
    "    #run[\"valid/bleu\"].append(bleu_score)\n",
    "    #run[\"valid/meteor\"].append(meteor_score)\n",
    "    #run[\"valid/rouge\"].append(rouge_score)\n",
    "    #print(f\"Epoch: {epoch}, BLEU: {bleu_score}, METEOR: {meteor_score}, ROUGE-L: {rouge_score}\")\n",
    "    \n",
    "run[\"score/final_loss\"] = np.round(loss_all / len(train_dataloader), 4)\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score, meteor_score, rouge_score = evaluate_model_on_metrics(model, valid_dataloader, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.754 METEOR: 0.811, ROUGE: 0.864\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU: {bleu_score} METEOR: {meteor_score}, ROUGE: {rouge_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
