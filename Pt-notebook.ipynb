{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "from datasets import load_metric\n",
    "\n",
    "print(load_dotenv(dotenv_path='../'))\n",
    "#from custom_utils.custom_pytorch_utils import TranslationDataset, collate_fn, evaluate_model_on_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"model/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/tokenizer/\")\n",
    "print(device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\urbii\\AppData\\Local\\Temp\\ipykernel_41192\\1174947439.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"bleu\", trust_remote_code=True)\n",
      "Using the latest cached version of the module from C:\\Users\\urbii\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\bleu\\05eb00cc2401cfd07edf1c3b09cdcbee37d65e58d5dd07d9c3e0ee3725ddf7e4 (last modified on Thu Aug  1 13:11:03 2024) since it couldn't be found locally at bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\urbii\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\meteor\\66efa51c366195fce5b82fcd16a5295716fff778276b529048fed7ca742ec3d3 (last modified on Thu Aug  1 13:11:05 2024) since it couldn't be found locally at meteor, or remotely on the Hugging Face Hub.\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "Using the latest cached version of the module from C:\\Users\\urbii\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\rouge\\457c405cab0bd19db749b46bf15a1a3cff4d54f50e7ab868c293e5ece288425e (last modified on Thu Aug  1 13:11:49 2024) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "bleu_metric = load_metric(\"bleu\", trust_remote_code=True)\n",
    "meteor_metric = load_metric(\"meteor\", trust_remote_code=True)\n",
    "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 2)\n",
      "(182, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>mig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jaki ma Pan numer domu?</td>\n",
       "      <td>Jaki twÃ³j dom numer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czy ma Pani krewnych?</td>\n",
       "      <td>Ty krewni masz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jak nazywa siÄ™ prezydent polski?</td>\n",
       "      <td>Prezydent polska nazwisko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jakie Pani ma obywatelstwo?</td>\n",
       "      <td>Ty obywatelstwo jakie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gdzie mieszkasz?</td>\n",
       "      <td>Ty mieszkaÄ‡ gdzie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pl                        mig\n",
       "0           Jaki ma Pan numer domu?        Jaki twÃ³j dom numer\n",
       "1             Czy ma Pani krewnych?             Ty krewni masz\n",
       "2  Jak nazywa siÄ™ prezydent polski?  Prezydent polska nazwisko\n",
       "3       Jakie Pani ma obywatelstwo?      Ty obywatelstwo jakie\n",
       "4                  Gdzie mieszkasz?          Ty mieszkaÄ‡ gdzie"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/All_data.csv\")\n",
    "train_indices = data.sample(frac=0.85, random_state=42).index\n",
    "train_data = data.loc[train_indices].reset_index(drop=True)\n",
    "valid_data = data.drop(train_indices).reset_index(drop=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   12,   243,  9805,    61,    51,   142,  1247,  1124, 14288,     7,\n",
       "              0],\n",
       "         [  883,    45, 39906,     7,     0, 63429, 63429, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [ 5494, 17812,  1647,  1184,     2,     0, 63429, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  322,   487,   363,  3032,   172,     2,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [ 3049,  2320,   140, 11656,    26, 31941,     7,     0, 63429, 63429,\n",
       "          63429],\n",
       "         [  322,    26,  2586,    25,    83,    24,  1171,     2,     0, 63429,\n",
       "          63429],\n",
       "         [  116,  4878,   485, 10360,   490,    24,   432,    31,  1524,     2,\n",
       "              0],\n",
       "         [  362,   606,  7549,  1450,   111,   466,   461,  6252,    61,     7,\n",
       "              0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[  122,    66,  6074,  3392,  2010,  2979,  6166,   757,     0],\n",
       "         [27266,   548,     0, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [11248, 11952, 17812,  2031,     0, 63429, 63429, 63429, 63429],\n",
       "         [   50,   413,  4899,     0, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  811,    16,  3323,   472, 11656,   106,  1200,     0, 63429],\n",
       "         [  322, 12408,   142,  7494,    80,     0, 63429, 63429, 63429],\n",
       "         [10607, 35607,   432,  1524,   485,     0, 63429, 63429, 63429],\n",
       "         [  322,    51,   461,  6252,    19,   485,     0, 63429, 63429]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:30<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 3.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:29<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:29<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.8305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:29<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.5876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:29<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run()\n",
    "lr = 5e-5\n",
    "num_epochs = 5\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "run[\"hyperparameters/learning_rate\"] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "run[\"hyperparameters/optimizer\"] = \"Adam\"\n",
    "run[\"hyperparameters/betas\"] = stringify_unsupported(optimizer.state_dict()['param_groups'][0]['betas'])\n",
    "run[\"hyperparameters/eps\"] = optimizer.state_dict()['param_groups'][0]['eps']\n",
    "run[\"datasets/train\"].track_files(\"data/All_data.csv\")\n",
    "run[\"hyperparameters/num_epochs\"] = num_epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    loss_all = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_all += loss.item()\n",
    "    run[\"train/loss\"].append(np.round(loss_all / len(train_dataloader), 4))\n",
    "    print(f\"Epoch: {epoch + 1}, loss: {np.round(loss_all / len(train_dataloader), 4)}\")\n",
    "    \n",
    "run[\"score/final_loss\"] = np.round(loss_all / len(train_dataloader), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score, meteor_score, rouge_score = evaluate_model_on_metrics(model, valid_dataloader, tokenizer, bleu_metric, meteor_metric, rouge_metric, device)\n",
    "run[\"metrics/BLEU\"] = bleu_score\n",
    "run[\"metrics/METEOR\"] = meteor_score\n",
    "run[\"metrics/ROUQE\"] = rouge_score\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.704 METEOR: 0.788, ROUGE: 0.841\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU: {bleu_score} METEOR: {meteor_score}, ROUGE: {rouge_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
