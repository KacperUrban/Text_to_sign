{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "from datasets import load_metric\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"model/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/tokenizer/\")\n",
    "print(device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\urbii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\urbii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\urbii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bleu_metric = load_metric(\"bleu\", trust_remote_code=True)\n",
    "meteor_metric = load_metric(\"meteor\", trust_remote_code=True)\n",
    "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 2)\n",
      "(182, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>mig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Niedziela to dzień wolny od pracy.</td>\n",
       "      <td>Niedziela praca wolny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czy Pani rozumie co mówię?</td>\n",
       "      <td>Ja mówić ty rozumieć</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proszę się tu położyć.</td>\n",
       "      <td>Prosić ty położyć tu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Proszę usiąść ponieważ będziemy musieli napisa...</td>\n",
       "      <td>Ja prosić ty siadać wywiad pisać razem musieć</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bałam się o moją rodzinę</td>\n",
       "      <td>Ja rodzina bać co wydarzyć</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  pl  \\\n",
       "0                 Niedziela to dzień wolny od pracy.   \n",
       "1                         Czy Pani rozumie co mówię?   \n",
       "2                             Proszę się tu położyć.   \n",
       "3  Proszę usiąść ponieważ będziemy musieli napisa...   \n",
       "4                           Bałam się o moją rodzinę   \n",
       "\n",
       "                                             mig  \n",
       "0                          Niedziela praca wolny  \n",
       "1                           Ja mówić ty rozumieć  \n",
       "2                           Prosić ty położyć tu  \n",
       "3  Ja prosić ty siadać wywiad pisać razem musieć  \n",
       "4                     Ja rodzina bać co wydarzyć  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/All_data.csv\")\n",
    "train_indices = data.sample(frac=0.85).index\n",
    "train_data = data.loc[train_indices].reset_index(drop=True)\n",
    "valid_data = data.drop(train_indices).reset_index(drop=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, input_texts, target_texts, tokenizer):\n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer(self.input_texts[idx], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        targets = self.tokenizer(self.target_texts[idx], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        return {**inputs, \"labels\": targets[\"input_ids\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  700, 27744,    80, 16949, 20637,    43,  5640,    40,  1859, 13954,\n",
       "             40,     2,     0],\n",
       "         [  700, 12079,    22,  1122,  2000,     2,     0, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429],\n",
       "         [  322,    26,   606,  9847,  8607,     2,     0, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429],\n",
       "         [  322,   487,  7610,  1238,     2,     0, 63429, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429],\n",
       "         [  700, 13136,  2266,     2,     0, 63429, 63429, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429],\n",
       "         [  213,  7898,    90,   140,  1123, 11004, 38131,     7,     0, 63429,\n",
       "          63429, 63429, 63429],\n",
       "         [  362,   669,  6166, 15898,     7,     0, 63429, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429],\n",
       "         [ 3049,  2320,   140, 10055, 24616,     7,     0, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]),\n",
       " 'labels': tensor([[  811, 25450, 22688, 17809,  6141,   684,     0, 63429, 63429],\n",
       "         [ 2320,  3819,    21,   151,     0, 63429, 63429, 63429, 63429],\n",
       "         [  322, 14052,  9847,    26,  5765,     0, 63429, 63429, 63429],\n",
       "         [  322,    54,  4398,     0, 63429, 63429, 63429, 63429, 63429],\n",
       "         [19972, 11014,    80,     0, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  811, 22136,    19,  7561,    19,  7019,   106,  1200,     0],\n",
       "         [  811,  6166,   998,     0, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  811, 24616,  2010,     0, 63429, 63429, 63429, 63429, 63429]])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item['input_ids'].squeeze() for item in batch]\n",
    "    attention_mask = [item['attention_mask'].squeeze() for item in batch]\n",
    "    labels = [item['labels'].squeeze() for item in batch]\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "train_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_metrics(model, dataloader, tokenizer, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model.generate(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "            predictions = [tokenizer.decode(g, skip_special_tokens=True) for g in outputs]\n",
    "            references = [tokenizer.decode(g, skip_special_tokens=True) for g in batch[\"labels\"]]\n",
    "\n",
    "            all_preds.extend(predictions)\n",
    "            all_labels.extend(references)\n",
    "\n",
    "    # Tokenize predictions and references\n",
    "    all_preds_tokenized = [pred.split() for pred in all_preds]\n",
    "    all_labels_tokenized = [[label.split()] for label in all_labels]\n",
    "\n",
    "    # Compute metrics\n",
    "    bleu_score = np.round(bleu_metric.compute(predictions=all_preds_tokenized, references=all_labels_tokenized), 3)\n",
    "    meteor_score = np.round(meteor_metric.compute(predictions=all_preds, references=all_labels), 3)\n",
    "    rouge_score = np.round(rouge_metric.compute(predictions=all_preds, references=all_labels), 3)\n",
    "\n",
    "    return bleu_score, meteor_score, rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:11<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.8986\n",
      "Epoch: 0, BLEU: 0.5203396170541483, METEOR: 0.6965631173017779, ROUGE-L: 0.776431939879722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:10<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.4709\n",
      "Epoch: 1, BLEU: 0.6676348630138037, METEOR: 0.7729933271479248, ROUGE-L: 0.832503478069937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:10<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.2845\n",
      "Epoch: 2, BLEU: 0.7837010400328199, METEOR: 0.8259982354442593, ROUGE-L: 0.8762372350660732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:11<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.2196\n",
      "Epoch: 3, BLEU: 0.8165261506325275, METEOR: 0.8399752129966479, ROUGE-L: 0.8874548294879647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:10<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.1753\n",
      "Epoch: 4, BLEU: 0.8382393973387714, METEOR: 0.8440210643098864, ROUGE-L: 0.8906145136751651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:10<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.1485\n",
      "Epoch: 5, BLEU: 0.8237773666341363, METEOR: 0.8559493852755075, ROUGE-L: 0.899519585111904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:10<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 0.136\n",
      "Epoch: 6, BLEU: 0.850454779495627, METEOR: 0.853933588019353, ROUGE-L: 0.8984082055510618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:10<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss: 0.1269\n",
      "Epoch: 7, BLEU: 0.8311820908307257, METEOR: 0.8531668842461698, ROUGE-L: 0.8973131496385051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:11<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 0.124\n",
      "Epoch: 8, BLEU: 0.8550901223884615, METEOR: 0.8547328168102447, ROUGE-L: 0.8981729357458214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:11<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss: 0.1152\n",
      "Epoch: 9, BLEU: 0.8562555060906211, METEOR: 0.8541771268599927, ROUGE-L: 0.8981397651587153\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 5 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 5 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-30/metadata\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(tags=\"test run\")\n",
    "lr = 5e-5\n",
    "num_epochs = 10\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "run[\"hyperparameters/learning_rate\"] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "run[\"hyperparameters/optimizer\"] = \"Adam\"\n",
    "run[\"hyperparameters/betas\"] = stringify_unsupported(optimizer.state_dict()['param_groups'][0]['betas'])\n",
    "run[\"hyperparameters/eps\"] = optimizer.state_dict()['param_groups'][0]['eps']\n",
    "run[\"hyperparameters/weight_decay\"] = optimizer.state_dict()['param_groups'][0]['weight_decay']\n",
    "run[\"datasets/train\"].track_files(\"data/All_data.csv\")\n",
    "run[\"hyperparameters/num_epochs\"] = num_epochs\n",
    "run[\"sys/device\"] = device\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    loss_all = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_all += loss.item()\n",
    "    run[\"train/loss\"].append(np.round(loss_all / len(train_dataloader), 4))\n",
    "    print(f\"Epoch: {epoch}, loss: {np.round(loss_all / len(train_dataloader), 4)}\")\n",
    "\n",
    "    bleu_score, meteor_score, rouge_score = evaluate_model_on_metrics(model, valid_dataloader, tokenizer, device)\n",
    "    run[\"valid/bleu\"].append(bleu_score[\"bleu\"])\n",
    "    run[\"valid/meteor\"].append(meteor_score[\"meteor\"])\n",
    "    run[\"valid/rouge\"].append(rouge_score[\"rougeL\"].mid.fmeasure)\n",
    "    print(f\"Epoch: {epoch}, BLEU: {bleu_score['bleu']}, METEOR: {meteor_score['meteor']}, ROUGE-L: {rouge_score['rougeL'].mid.fmeasure}\")\n",
    "    \n",
    "run[\"score/final_loss\"] = np.round(loss_all / len(train_dataloader), 4)\n",
    "run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
