{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import neptune\n",
    "from neptune.utils import stringify_unsupported\n",
    "import evaluate\n",
    "from custom_utils.custom_pytorch_utils import TranslationDataset, collate_fn, evaluate_model_on_bleu\n",
    "\n",
    "print(load_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"model/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/tokenizer/\")\n",
    "print(device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 2)\n",
      "(182, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>mig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jaki ma Pan numer domu?</td>\n",
       "      <td>Jaki twój dom numer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Czy ma Pani krewnych?</td>\n",
       "      <td>Ty krewni masz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jak nazywa się prezydent polski?</td>\n",
       "      <td>Prezydent polska nazwisko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jakie Pani ma obywatelstwo?</td>\n",
       "      <td>Ty obywatelstwo jakie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gdzie mieszkasz?</td>\n",
       "      <td>Ty mieszkać gdzie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pl                        mig\n",
       "0           Jaki ma Pan numer domu?        Jaki twój dom numer\n",
       "1             Czy ma Pani krewnych?             Ty krewni masz\n",
       "2  Jak nazywa się prezydent polski?  Prezydent polska nazwisko\n",
       "3       Jakie Pani ma obywatelstwo?      Ty obywatelstwo jakie\n",
       "4                  Gdzie mieszkasz?          Ty mieszkać gdzie"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/final_data/all_data.csv\")\n",
    "train_indices = data.sample(frac=0.85, random_state=42).index\n",
    "train_data = data.loc[train_indices].reset_index(drop=True)\n",
    "valid_data = data.drop(train_indices).reset_index(drop=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  322,    26,    18,    78,    25,  5898, 17983,   788,     2,     0,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  230,  5986,   151,    54,  2227,    17,   581,    25,  2160,     9,\n",
       "           7688,  1549, 22251,    10, 10260,     2,     0],\n",
       "         [  926,  5171,  1117,  7866,   100,  3567,     7,     0, 63429, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [ 3049,   140,  2320,  2601, 14288, 18334,     7,     0, 63429, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [ 1123,   538, 11413, 20930,   969,    18,   127,     2,     0, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  362,  2320,    45,    88,   389,  2948,   398,     7,     0, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [  926,  2320, 17579,  7959,  1810,     7,     0, 63429, 63429, 63429,\n",
       "          63429, 63429, 63429, 63429, 63429, 63429, 63429],\n",
       "         [ 3939,   456,   148,  3412,    17,    26,   606,  5551,   550, 13677,\n",
       "              2,     0, 63429, 63429, 63429, 63429, 63429]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]),\n",
       " 'labels': tensor([[ 6714, 17983,   343,   307,    26,  4998,    80,     0, 63429, 63429,\n",
       "          63429],\n",
       "         [  230,  5986,    15,  2313,   151,   307,    10,    15, 17525,   203,\n",
       "              0],\n",
       "         [  834,  7866,   100,  3567, 15057,   535,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [ 2320,  6166,  2601,  1852,     0, 63429, 63429, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [ 1123, 20930,   969,    18,   127, 17794,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  811,    88,   389,  1172,    80,     0, 63429, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  811,  7959,  1810, 17579,    55,   535,     0, 63429, 63429, 63429,\n",
       "          63429],\n",
       "         [  322, 13677,    19,  5551,  7879,  2237,  3472,   357,    96,     0,\n",
       "          63429]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset = TranslationDataset(train_data.pl, train_data.mig, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:24<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 3.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:25<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:25<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.8305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:25<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:24<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run()\n",
    "lr = 5e-5\n",
    "num_epochs = 5\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "run[\"hyperparameters/learning_rate\"] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "run[\"hyperparameters/optimizer\"] = \"Adam\"\n",
    "run[\"hyperparameters/betas\"] = stringify_unsupported(optimizer.state_dict()['param_groups'][0]['betas'])\n",
    "run[\"hyperparameters/eps\"] = optimizer.state_dict()['param_groups'][0]['eps']\n",
    "run[\"datasets/train\"].track_files(\"data/final_data/all_data.csv\")\n",
    "run[\"hyperparameters/num_epochs\"] = num_epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    loss_all = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_all += loss.item()\n",
    "    run[\"train/loss\"].append(np.round(loss_all / len(train_dataloader), 4))\n",
    "    print(f\"Epoch: {epoch + 1}, loss: {np.round(loss_all / len(train_dataloader), 4)}\")\n",
    "    \n",
    "run[\"score/final_loss\"] = np.round(loss_all / len(train_dataloader), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 1 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-40/metadata\n"
     ]
    }
   ],
   "source": [
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "bleu_score = evaluate_model_on_bleu(model, valid_dataloader, tokenizer, bleu_metric, device, None)\n",
    "run[\"metrics/BLEU\"] = bleu_score\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.659\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU: {bleu_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
