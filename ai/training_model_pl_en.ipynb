{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load pretrained model locally"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-19 11:09:55.632264: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-19 11:09:55.944913: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-19 11:09:55.946245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 11:09:57.063211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at ./model/model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./model/tokenizer\")\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"./model/model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T11:10:01.622580057Z",
     "start_time": "2023-05-19T11:09:53.881844647Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_marian_mt_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFMarianMainLayer)   multiple                  77138944  \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 63430     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,202,374\n",
      "Trainable params: 77,138,944\n",
      "Non-trainable params: 63,430\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:35:41.646113025Z",
     "start_time": "2023-05-08T17:35:41.612067319Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'model',\n 'trainable': True,\n 'dtype': 'float32',\n 'config': {'vocab_size': 63430,\n  'decoder_vocab_size': 63430,\n  'max_position_embeddings': 512,\n  'd_model': 512,\n  'encoder_ffn_dim': 2048,\n  'encoder_layers': 6,\n  'encoder_attention_heads': 8,\n  'decoder_ffn_dim': 2048,\n  'decoder_layers': 6,\n  'decoder_attention_heads': 8,\n  'dropout': 0.1,\n  'attention_dropout': 0.0,\n  'activation_dropout': 0.0,\n  'activation_function': 'swish',\n  'init_std': 0.02,\n  'encoder_layerdrop': 0.0,\n  'decoder_layerdrop': 0.0,\n  'use_cache': True,\n  'num_hidden_layers': 6,\n  'scale_embedding': True,\n  'share_encoder_decoder_embeddings': True,\n  'return_dict': True,\n  'output_hidden_states': False,\n  'output_attentions': False,\n  'torchscript': False,\n  'torch_dtype': None,\n  'use_bfloat16': False,\n  'tf_legacy_loss': False,\n  'pruned_heads': {},\n  'tie_word_embeddings': True,\n  'is_encoder_decoder': True,\n  'is_decoder': False,\n  'cross_attention_hidden_size': None,\n  'add_cross_attention': False,\n  'tie_encoder_decoder': False,\n  'max_length': 512,\n  'min_length': 0,\n  'do_sample': False,\n  'early_stopping': False,\n  'num_beams': 6,\n  'num_beam_groups': 1,\n  'diversity_penalty': 0.0,\n  'temperature': 1.0,\n  'top_k': 50,\n  'top_p': 1.0,\n  'typical_p': 1.0,\n  'repetition_penalty': 1.0,\n  'length_penalty': 1.0,\n  'no_repeat_ngram_size': 0,\n  'encoder_no_repeat_ngram_size': 0,\n  'bad_words_ids': [[63429]],\n  'num_return_sequences': 1,\n  'chunk_size_feed_forward': 0,\n  'output_scores': False,\n  'return_dict_in_generate': False,\n  'forced_bos_token_id': None,\n  'forced_eos_token_id': 0,\n  'remove_invalid_values': False,\n  'exponential_decay_length_penalty': None,\n  'suppress_tokens': None,\n  'begin_suppress_tokens': None,\n  'architectures': ['MarianMTModel'],\n  'finetuning_task': None,\n  'id2label': {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'},\n  'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2},\n  'tokenizer_class': None,\n  'prefix': None,\n  'bos_token_id': 0,\n  'pad_token_id': 63429,\n  'eos_token_id': 0,\n  'sep_token_id': None,\n  'decoder_start_token_id': 63429,\n  'task_specific_params': None,\n  'problem_type': None,\n  '_name_or_path': './model/model.h5',\n  'transformers_version': '4.27.4',\n  '_num_labels': 3,\n  'add_bias_logits': False,\n  'add_final_layer_norm': False,\n  'classif_dropout': 0.0,\n  'classifier_dropout': 0.0,\n  'model_type': 'marian',\n  'normalize_before': False,\n  'normalize_embedding': False,\n  'static_position_embeddings': True}}"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:35:42.259373108Z",
     "start_time": "2023-05-08T17:35:42.248668957Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'encoder',\n 'trainable': True,\n 'dtype': 'float32',\n 'config': {'vocab_size': 63430,\n  'decoder_vocab_size': 63430,\n  'max_position_embeddings': 512,\n  'd_model': 512,\n  'encoder_ffn_dim': 2048,\n  'encoder_layers': 6,\n  'encoder_attention_heads': 8,\n  'decoder_ffn_dim': 2048,\n  'decoder_layers': 6,\n  'decoder_attention_heads': 8,\n  'dropout': 0.1,\n  'attention_dropout': 0.0,\n  'activation_dropout': 0.0,\n  'activation_function': 'swish',\n  'init_std': 0.02,\n  'encoder_layerdrop': 0.0,\n  'decoder_layerdrop': 0.0,\n  'use_cache': True,\n  'num_hidden_layers': 6,\n  'scale_embedding': True,\n  'share_encoder_decoder_embeddings': True,\n  'return_dict': True,\n  'output_hidden_states': False,\n  'output_attentions': False,\n  'torchscript': False,\n  'torch_dtype': None,\n  'use_bfloat16': False,\n  'tf_legacy_loss': False,\n  'pruned_heads': {},\n  'tie_word_embeddings': True,\n  'is_encoder_decoder': True,\n  'is_decoder': False,\n  'cross_attention_hidden_size': None,\n  'add_cross_attention': False,\n  'tie_encoder_decoder': False,\n  'max_length': 512,\n  'min_length': 0,\n  'do_sample': False,\n  'early_stopping': False,\n  'num_beams': 6,\n  'num_beam_groups': 1,\n  'diversity_penalty': 0.0,\n  'temperature': 1.0,\n  'top_k': 50,\n  'top_p': 1.0,\n  'typical_p': 1.0,\n  'repetition_penalty': 1.0,\n  'length_penalty': 1.0,\n  'no_repeat_ngram_size': 0,\n  'encoder_no_repeat_ngram_size': 0,\n  'bad_words_ids': [[63429]],\n  'num_return_sequences': 1,\n  'chunk_size_feed_forward': 0,\n  'output_scores': False,\n  'return_dict_in_generate': False,\n  'forced_bos_token_id': None,\n  'forced_eos_token_id': 0,\n  'remove_invalid_values': False,\n  'exponential_decay_length_penalty': None,\n  'suppress_tokens': None,\n  'begin_suppress_tokens': None,\n  'architectures': ['MarianMTModel'],\n  'finetuning_task': None,\n  'id2label': {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'},\n  'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2},\n  'tokenizer_class': None,\n  'prefix': None,\n  'bos_token_id': 0,\n  'pad_token_id': 63429,\n  'eos_token_id': 0,\n  'sep_token_id': None,\n  'decoder_start_token_id': 63429,\n  'task_specific_params': None,\n  'problem_type': None,\n  '_name_or_path': './model/model.h5',\n  'transformers_version': '4.27.4',\n  '_num_labels': 3,\n  'add_bias_logits': False,\n  'add_final_layer_norm': False,\n  'classif_dropout': 0.0,\n  'classifier_dropout': 0.0,\n  'model_type': 'marian',\n  'normalize_before': False,\n  'normalize_embedding': False,\n  'static_position_embeddings': True}}"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:35:42.710491809Z",
     "start_time": "2023-05-08T17:35:42.700919059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl - en\n",
      "Max lenght: 512\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.source_lang, \"-\", tokenizer.target_lang)\n",
    "print(f\"Max lenght: {tokenizer.model_max_length}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:35:43.563797955Z",
     "start_time": "2023-05-08T17:35:43.557197212Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The attempt of implementation a transfer learning on a model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data from file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "# Wczytanie plikÃ³w z danymi\n",
    "with open(\"dataset/polish.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    polish_data = f.read().splitlines()\n",
    "\n",
    "with open(\"dataset/english.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    english_data = f.read().splitlines()\n",
    "\n",
    "raw_dataset_list = []\n",
    "for i in range(0, 30000):\n",
    "    raw_dataset_list.append({'translation' : {'pl' : polish_data[i], 'en' : english_data[i]}})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:35:55.464427816Z",
     "start_time": "2023-05-08T17:35:54.138344595Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['translation'],\n    num_rows: 30000\n})"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "raw_dataset = Dataset.from_list(raw_dataset_list)\n",
    "raw_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:35:58.080147975Z",
     "start_time": "2023-05-08T17:35:58.048677709Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data into train, validation and test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 27000\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 1500\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 1500\n    })\n})"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_testvalid = raw_dataset.train_test_split(test_size=0.1)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'validation': test_valid['train']})\n",
    "train_test_valid_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:36:40.479568784Z",
     "start_time": "2023-05-08T17:36:40.455878256Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create preprocessing function for our data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 512\n",
    "source_lang = \"pl\"\n",
    "target_lang = \"en\"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:36:48.977036118Z",
     "start_time": "2023-05-08T17:36:48.969952302Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[8327, 26830, 11601, 10, 8821, 124, 2, 51, 8246, 90, 3429, 8107, 4166, 61, 22710, 3, 1011, 3492, 45, 23967, 1213, 22710, 14439, 17, 15224, 42047, 1657, 23315, 7256, 3565, 22710, 16405, 2, 0], [3061, 655, 511, 981, 162, 7375, 356, 37105, 29, 22187, 10117, 126, 23554, 10753, 2, 2744, 3646, 25, 25688, 19, 278, 6428, 95, 43, 816, 11237, 143, 7868, 1087, 17, 20685, 27769, 103, 41821, 15, 5010, 1805, 5954, 21321, 28, 24459, 8332, 8102, 3, 30157, 3, 32656, 17, 38267, 38, 17, 887, 550, 33664, 34782, 39857, 2228, 17, 20475, 18, 466, 2171, 7255, 25, 23333, 134, 7868, 579, 46354, 19396, 8852, 98, 3, 10262, 2668, 3, 7098, 48330, 3, 20497, 29, 3, 15, 10407, 10822, 17, 13734, 3, 5621, 3, 33533, 19, 5352, 2, 234, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[52, 483, 2233, 19214, 713, 9062, 8, 1348, 9, 13, 33155, 4130, 3, 713, 17516, 8, 34473, 13, 12954, 3, 14, 7344, 8, 9768, 45019, 3, 14, 12932, 8, 4875, 20256, 3, 108, 14, 13247, 85, 1962, 1308, 20256, 3, 129, 2275, 14, 13247, 24076, 806, 3, 129, 18482, 773, 71, 7033, 43061, 3, 4, 1949, 2793, 32, 18132, 7928, 11279, 29882, 6870, 5624, 3574, 40720, 3139, 13, 14, 1659, 8, 8579, 27389, 22177, 110, 6075, 2, 0], [1060, 56, 4218, 3, 4, 3680, 1, 9, 400, 244, 1628, 5199, 118, 8749, 82, 4674, 9, 1164, 28, 7788, 9352, 13, 6103, 9352, 3, 615, 72, 6711, 3912, 8, 102, 1914, 5533, 13, 882, 2327, 49847, 53, 4, 30877, 3680, 3, 1293, 8, 6571, 3, 5860, 50688, 33, 4, 30877, 3680, 3485, 33, 882, 7058, 3, 461, 9, 9, 13764, 281, 670, 2338, 2769, 70, 94, 1105, 51675, 65, 0]]}"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(train_test_valid_dataset[\"train\"][:2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:36:50.620564973Z",
     "start_time": "2023-05-08T17:36:50.614093039Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Map preprocess function on our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = train_test_valid_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:37:02.560220959Z",
     "start_time": "2023-05-08T17:36:53.371954456Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
    "train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "validation_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_dataset[\"validation\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "test_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:37:04.475971925Z",
     "start_time": "2023-05-08T17:37:04.177111029Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'encoder',\n 'trainable': False,\n 'dtype': 'float32',\n 'config': {'vocab_size': 63430,\n  'decoder_vocab_size': 63430,\n  'max_position_embeddings': 512,\n  'd_model': 512,\n  'encoder_ffn_dim': 2048,\n  'encoder_layers': 6,\n  'encoder_attention_heads': 8,\n  'decoder_ffn_dim': 2048,\n  'decoder_layers': 6,\n  'decoder_attention_heads': 8,\n  'dropout': 0.1,\n  'attention_dropout': 0.0,\n  'activation_dropout': 0.0,\n  'activation_function': 'swish',\n  'init_std': 0.02,\n  'encoder_layerdrop': 0.0,\n  'decoder_layerdrop': 0.0,\n  'use_cache': True,\n  'num_hidden_layers': 6,\n  'scale_embedding': True,\n  'share_encoder_decoder_embeddings': True,\n  'return_dict': True,\n  'output_hidden_states': False,\n  'output_attentions': False,\n  'torchscript': False,\n  'torch_dtype': None,\n  'use_bfloat16': False,\n  'tf_legacy_loss': False,\n  'pruned_heads': {},\n  'tie_word_embeddings': True,\n  'is_encoder_decoder': True,\n  'is_decoder': False,\n  'cross_attention_hidden_size': None,\n  'add_cross_attention': False,\n  'tie_encoder_decoder': False,\n  'max_length': 512,\n  'min_length': 0,\n  'do_sample': False,\n  'early_stopping': False,\n  'num_beams': 6,\n  'num_beam_groups': 1,\n  'diversity_penalty': 0.0,\n  'temperature': 1.0,\n  'top_k': 50,\n  'top_p': 1.0,\n  'typical_p': 1.0,\n  'repetition_penalty': 1.0,\n  'length_penalty': 1.0,\n  'no_repeat_ngram_size': 0,\n  'encoder_no_repeat_ngram_size': 0,\n  'bad_words_ids': [[63429]],\n  'num_return_sequences': 1,\n  'chunk_size_feed_forward': 0,\n  'output_scores': False,\n  'return_dict_in_generate': False,\n  'forced_bos_token_id': None,\n  'forced_eos_token_id': 0,\n  'remove_invalid_values': False,\n  'exponential_decay_length_penalty': None,\n  'suppress_tokens': None,\n  'begin_suppress_tokens': None,\n  'architectures': ['MarianMTModel'],\n  'finetuning_task': None,\n  'id2label': {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'},\n  'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2},\n  'tokenizer_class': None,\n  'prefix': None,\n  'bos_token_id': 0,\n  'pad_token_id': 63429,\n  'eos_token_id': 0,\n  'sep_token_id': None,\n  'decoder_start_token_id': 63429,\n  'task_specific_params': None,\n  'problem_type': None,\n  '_name_or_path': './model/model.h5',\n  'transformers_version': '4.27.4',\n  '_num_labels': 3,\n  'add_bias_logits': False,\n  'add_final_layer_norm': False,\n  'classif_dropout': 0.0,\n  'classifier_dropout': 0.0,\n  'model_type': 'marian',\n  'normalize_before': False,\n  'normalize_embedding': False,\n  'static_position_embeddings': True}}"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.trainable = False\n",
    "model.model.encoder.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:37:11.061428055Z",
     "start_time": "2023-05-08T17:37:11.055785009Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "for layer in model.model.decoder.layers[:5]:\n",
    "    layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:37:13.318113932Z",
     "start_time": "2023-05-08T17:37:13.314415485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_marian_mt_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFMarianMainLayer)   multiple                  77138944  \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 63430     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,202,374\n",
      "Trainable params: 4,466,176\n",
      "Non-trainable params: 72,736,198\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:37:13.997611709Z",
     "start_time": "2023-05-08T17:37:13.960034553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile( optimizer=optimizer, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T17:37:22.366070261Z",
     "start_time": "2023-05-08T17:37:22.354663258Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 17:37:23.905907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [27000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-08 17:37:23.906159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [27000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-08 17:37:25.292947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n",
      "2023-05-08 17:37:25.293051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n",
      "2023-05-08 17:37:25.341932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/add/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/add/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n",
      "2023-05-08 17:37:32.191312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n",
      "2023-05-08 17:37:32.191473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n",
      "2023-05-08 17:37:32.218879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/add/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/add/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 352/1687 [=====>........................] - ETA: 1:11:54 - loss: 8.6114 - accuracy: 0.0174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 17:56:40.545663: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 994582400 exceeds 10% of free system memory.\n",
      "2023-05-08 17:56:42.689358: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 994582400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 355/1687 [=====>........................] - ETA: 1:12:17 - loss: 8.6017 - accuracy: 0.0173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 17:56:59.685891: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1027058560 exceeds 10% of free system memory.\n",
      "2023-05-08 17:57:01.814853: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1027058560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 664/1687 [==========>...................] - ETA: 56:24 - loss: 8.0083 - accuracy: 0.0223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 18:14:21.091464: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1108248960 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687/1687 [==============================] - ETA: 0s - loss: 7.5375 - accuracy: 0.0259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 19:16:12.597482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1500]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-08 19:16:14.264392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice_1' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice_1}}]]\n",
      "2023-05-08 19:16:14.264509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice_1' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice_1}}]]\n",
      "2023-05-08 19:16:14.288208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/Tile/multiples/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/Tile/multiples/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n",
      "2023-05-08 19:16:14.297192: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/ones/packed/tf_marian_mt_model_2/model/decoder/strided_slice}}]]\n",
      "2023-05-08 19:16:14.306991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model_2/model/decoder/cond/add/tf_marian_mt_model_2/model/decoder/strided_slice_1' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model_2/model/decoder/cond/add/tf_marian_mt_model_2/model/decoder/strided_slice_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687/1687 [==============================] - 6141s 4s/step - loss: 7.5375 - accuracy: 0.0259 - val_loss: 7.1420 - val_accuracy: 0.0285\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f764e46b490>"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T19:19:45.081025127Z",
     "start_time": "2023-05-08T17:37:23.909291008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
