{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e90ad30c09b9dc77"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from odf.opendocument import load\n",
    "from odf import text, teletype\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from tensorflow import keras\n",
    "import neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:55:54.429586635Z",
     "start_time": "2023-10-09T13:55:54.417097566Z"
    }
   },
   "id": "46b5512e5c528ccf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data from .odt format"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd35bdf3cf4e919"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:55:59.624821540Z",
     "start_time": "2023-10-09T13:55:59.610915544Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    raw_data = []\n",
    "    text_doc = load(filepath)\n",
    "    all_params = text_doc.getElementsByType(text.P)\n",
    "    for line in all_params:\n",
    "        raw_data.append(teletype.extractText(line))\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['Wypowiedzi OG',\n 'Przywitanie',\n '- Dzień dobry.',\n '[',\n 'dzień dobry',\n 'witać',\n ']',\n 'Wyjaśnienie powodu wizyty',\n '- Chcę złożyć wniosek o wydanie dowodu osobistego.',\n '[',\n 'ja wniosek dowód1 mieć',\n 'ja wniosek dowód2 mieć',\n ']',\n '- Czy mogę odebrać dowód?',\n '[',\n 'czy już nowy dowód1',\n 'czy już nowy dowód2',\n 'być mój nowy dowód1',\n 'być mój nowy dowód2',\n ']',\n '- Chcę zgłosić utratę dowodu osobistego.',\n '[',\n 'ja dowód1 zgubić',\n 'ja dowód2 zgubić',\n ']',\n '- Chcę złożyć wniosek o wydanie dowodu osobistego dla mojego dziecka.',\n '[',\n 'ja dowód1 moje dziecko chcieć',\n 'ja dowód2 moje dziecko chcieć',\n ']',\n '- Chcę złożyć wniosek o wydanie dowodu osobistego dla mojej żony.',\n '[',\n 'ja dowód1 moja żona chcieć',\n 'ja dowód2 moja żona chcieć',\n ']',\n 'Obsługa',\n '- Zmieniłem adres.',\n '[',\n 'dom przenieść się',\n 'mieszkanie zmiana1',\n 'mieszkanie zmiana2',\n 'adres1 zmiana1',\n 'adres2 zmiana1',\n 'adres1 zmiana2',\n 'adres2 zmiana2',\n ']',\n '- Upłynął termin ważności dowodu.',\n '[',\n 'dowód1 nieważny',\n 'dowód2 nieważny',\n 'dowód1 koniec ważny',\n 'dowód2 koniec ważny',\n ']',\n '- Z powodu zmiany wizerunku twarzy.',\n '[',\n 'z powód zmiana wygląd',\n ']',\n '- Zawarłem(am) związek małżeński.',\n '[',\n 'ja małżeństwo',\n ']',\n '- Zmieniłem(am) nazwisko.',\n '[',\n 'ja zmiana1 nazwisko',\n 'ja zmiana2 nazwisko',\n ']',\n '- Decyzją zmieniłam nazwisko.',\n '[',\n ']',\n '- Powróciłam do nazwiska rodowego.',\n '[',\n 'ja przyjmować nazwisko panna',\n 'ja przyjmować nazwisko kawaler',\n ']',\n '- Nastąpiła zmiana imienia ojca.',\n '[',\n 'ojcieć imię zmiana1',\n 'ojcieć imię zmiana2',\n ']',\n '- Nastąpiła zmiana imienia matki.',\n '[',\n 'matka imię zmiana1',\n 'matka imię zmiana2',\n ']',\n '- Tak.',\n '[',\n 'tak',\n ']',\n '- Dlaczego?',\n '[',\n 'dlaczego',\n ']',\n '- Nie.',\n '[',\n 'nie',\n ']',\n '- Dziękuję.',\n '[',\n 'dziękować1',\n 'dziękować2',\n ']',\n '- Nie umiem wypełnić wniosku.',\n '[',\n 'ja nie wiedzieć wypełnić',\n ']',\n '- Proszę.',\n '[',\n 'prosić',\n ']',\n '- Nie mam dowodu.',\n '[',\n 'niemieć dowód1',\n 'niemieć dowód2',\n ']',\n '- Nie zabrałem ze sobą dowodu.',\n '[',\n 'niemieć dowód1',\n 'niemieć dowód2',\n ']',\n '- To mój pierwszy dowód.',\n '[',\n 'ja pierwszy raz dowód1 robić',\n 'ja pierwszy raz dowód2 robić',\n ']',\n '- Nie mam zdjęcia.',\n '[',\n 'niemieć zdjęcie',\n 'zdjęcie niemieć',\n ']',\n '- Czy można zgłosić się wcześniej?',\n '[',\n 'dowód1 odbiór wcześniej można',\n 'dowód2 odbiór wcześniej można',\n ']',\n '- Czy można przyśpieszyć produkcję dowodu?',\n '[',\n 'dowód1 wcześniej gotowy można',\n 'dowód2 wcześniej gotowy można',\n ']',\n '- Ile płacę za wyrobienie dowodu?',\n '[',\n 'nowy dowód1 płacić ile',\n 'nowy dowód2 płacić ile',\n ']',\n '- Nie umiem wypełnić formularza.',\n '[',\n 'formularz wypełnić nieumieć',\n ']',\n '- Mam uszkodzony dowód.',\n '[',\n 'mój dowód1 pękąć',\n 'mój dowód2 pękąć',\n 'mój dowód1 psuć',\n 'mój dowód2 psuć',\n 'mój dowód1 zniszczyć',\n 'mój dowód2 zniszczyć',\n ']',\n 'Pożegnanie',\n '- Do widzenia.',\n '[',\n 'do widzenia',\n ']',\n 'Dodatkowe',\n '- Chcę złożyć wniosek o wydanie dowodu osobistego.',\n '[',\n 'chcieć nowy dowód1',\n 'chcieć nowy dowód2',\n 'nowy dowód1 chcieć',\n 'nowy dowód2 chcieć',\n ']',\n '- Czy mogę odebrać dowód?',\n '[',\n 'dowód1 gotowy',\n 'dowód2 gotowy',\n ']',\n '- Nie umiem wypełnić wniosku.',\n '[',\n 'papier wniosek wypełnić jak',\n ']',\n '- Nie umiem wypełnić wniosku.',\n '[',\n 'ja nie rozumieć co to być',\n 'ja nie rozumieć co pisac',\n ']',\n '- Nie umiem wypełnić wniosku.',\n '[',\n 'nie rozumieć to',\n 'niewiedzieć to',\n 'nie rozumieć - pomysł',\n ']',\n '- Nie umiem wypełnić wniosku.',\n '[',\n 'co pisać mieć',\n 'jak pisać mieć',\n ']',\n '- Proszę mi pomóc.',\n '[',\n 'prosić pomagać ja',\n 'ja niewiedzieć prosić pomagać ja pusto',\n ']',\n '- Ile płacę za wyrobienie dowodu?',\n '[',\n 'pieniądze ile nowy dowód1',\n 'pieniądze ile nowy dowód2',\n 'ile koszt nowy dowód1',\n 'ile koszt nowy dowód2',\n ']',\n '- Ile płacę za wyrobienie dowodu?',\n '[',\n 'ile płacić dowód1',\n 'ile płacić dowód2',\n ']',\n '- Nie jestem zameldowany w Rzeszowie, czy mogę tutaj złożyć wniosek na dowód osobisty.',\n '[',\n 'Ja Rzeszów zameldowanie niemieć wniosek dowód1 dać można',\n 'Ja Rzeszów zameldowanie niemieć wniosek dowód2 dać można',\n 'Ja Rzeszów zameldowanie niemieć wniosek dowód1 złożyć można',\n 'Ja Rzeszów zameldowanie niemieć wniosek dowód2 złożyć można',\n ']',\n '- Proszę powtórzyć.',\n '[',\n 'powtarzać prosić',\n 'prosić powtarzać',\n ']',\n '- Chcę złożyć wniosek o wydanie dowodu osobistego.',\n '[',\n 'tu zmiana dowód1',\n 'tu zmiana dowód2',\n ']',\n '- Poproszę o wniosek.',\n '[',\n 'prosić wniosek',\n 'prosić wniosek dowód1',\n 'prosić wniosek dowód2',\n 'dowód1 wniosek prosić',\n 'dowód2 wniosek prosić',\n ']',\n '- Chcę złożyć wniosek o wydanie dowodu osobistego.',\n '[',\n 'papier wniosek mieć',\n ']',\n '- Chcę złożyć wniosek o wydanie dowodu osobistego.',\n '[',\n 'przyjść papier wniosek mieć',\n ']',\n '- Czy moje zdjęcie jest dobre?',\n '[',\n 'zdjęcie dobre',\n ']',\n '- Ile zdjęć potrzeba?',\n '[',\n 'ile sztuk zdjęcie potrzeba',\n ']',\n '- Jakie zdjęcie jest potrzebne?',\n '[',\n 'jakie zdjęcie podać potrzeba',\n 'jakie zdjęcie pokazać potrzeba',\n ']',\n '- Jak długo trzeba czekać?',\n '[',\n 'jak długo czekać',\n 'ile dni czekać',\n 'kiedy gotowy dowód1',\n 'kiedy gotowy dowód2',\n ']',\n '- Czy muszę sam odebrać dowód?',\n '[',\n 'musieć ja odebrać dowód1',\n 'musieć ja odebrać dowód2',\n ']',\n '- Zgubiłem dowód.',\n '[',\n 'dowód1 zgubić',\n 'dowód2 zgubić',\n 'zgubić dowód1',\n 'zgubić dowód2',\n ']',\n '- Mam stary dowód.',\n '[',\n 'stary dowód1 mieć',\n 'stary dowód2 mieć',\n ']',\n '- Zmieniłem(am) nazwisko.',\n '[',\n 'nazwisko zmiana1',\n 'nazwisko zmiana2',\n 'przeniesc inne spać',\n 'już ślub',\n ']',\n '- Mam 18 lat.',\n '[',\n 'już 18 lat',\n ']',\n '- Mam paszport.',\n '[',\n 'paszport mieć',\n ']']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = load_data('dataset/data.odt')\n",
    "while '' in raw_data:\n",
    "    raw_data.remove('')\n",
    "raw_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:56:01.480497139Z",
     "start_time": "2023-10-09T13:56:01.439202421Z"
    }
   },
   "id": "4d17a438678e549"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load model and tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a8e135c67c6e659"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 13:56:17.230601: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 129904640 exceeds 10% of free system memory.\n",
      "2023-10-09 13:56:17.456863: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 129904640 exceeds 10% of free system memory.\n",
      "2023-10-09 13:56:17.480317: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 129904640 exceeds 10% of free system memory.\n",
      "2023-10-09 13:56:19.686132: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 129904640 exceeds 10% of free system memory.\n",
      "2023-10-09 13:56:20.211797: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 129904640 exceeds 10% of free system memory.\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at ./model/model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./model/tokenizer\")\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"./model/model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:56:21.061260226Z",
     "start_time": "2023-10-09T13:56:16.681506509Z"
    }
   },
   "id": "c1dc505bbfc6128f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adjust data form to our model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96f85ddbd2132bd3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def split_data_from_list(raw_data):\n",
    "    pl_sentence = []\n",
    "    sentence = []\n",
    "    i=0\n",
    "    while i < len(raw_data):\n",
    "        if raw_data[i+1] == '[':\n",
    "            value = raw_data[i]\n",
    "            i += 2\n",
    "            while i < len(raw_data):\n",
    "                if raw_data[i] == ']':\n",
    "                    break\n",
    "                pl_sentence.append(value[1:])\n",
    "                sentence.append(raw_data[i])\n",
    "                i += 1\n",
    "        i += 1\n",
    "    return pl_sentence, sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:56:32.885754402Z",
     "start_time": "2023-10-09T13:56:32.870855666Z"
    }
   },
   "id": "b7362121004c1d7f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "s1, s2 = split_data_from_list(raw_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:56:34.035379342Z",
     "start_time": "2023-10-09T13:56:34.030865036Z"
    }
   },
   "id": "405202227019684b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  pl                     mig\n",
      "0                                       Dzień dobry.             dzień dobry\n",
      "1                                       Dzień dobry.                   witać\n",
      "2   Chcę złożyć wniosek o wydanie dowodu osobistego.  ja wniosek dowód1 mieć\n",
      "3   Chcę złożyć wniosek o wydanie dowodu osobistego.  ja wniosek dowód2 mieć\n",
      "4                            Czy mogę odebrać dowód?     czy już nowy dowód1\n",
      "5                            Czy mogę odebrać dowód?     czy już nowy dowód2\n",
      "6                            Czy mogę odebrać dowód?     być mój nowy dowód1\n",
      "7                            Czy mogę odebrać dowód?     być mój nowy dowód2\n",
      "8             Chcę zgłosić utratę dowodu osobistego.        ja dowód1 zgubić\n",
      "9             Chcę zgłosić utratę dowodu osobistego.        ja dowód2 zgubić\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'pl':s1, 'mig':s2})\n",
    "print(data[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:56:34.863758871Z",
     "start_time": "2023-10-09T13:56:34.812609767Z"
    }
   },
   "id": "cb405ef16a871d7e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "430617ae1a0d0cb0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['translation'],\n    num_rows: 123\n})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset_list = []\n",
    "for i in range(0, len(data)):\n",
    "    raw_dataset_list.append({'translation' : {'pl' : data['pl'][i], 'mig' : data['mig'][i]}})\n",
    "    \n",
    "raw_dataset = Dataset.from_list(raw_dataset_list)\n",
    "raw_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:56:37.622190086Z",
     "start_time": "2023-10-09T13:56:37.541576845Z"
    }
   },
   "id": "ab17742cb745d864"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data into train, validation and test dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c2762491b9cd97a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 92\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 31\n    })\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test = raw_dataset.train_test_split(test_size=0.25)\n",
    "\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': train_test['test']})\n",
    "train_test_valid_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:56:51.966481689Z",
     "start_time": "2023-10-09T13:56:51.954465088Z"
    }
   },
   "id": "5726fd5d5384354"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create preprocessing function for our data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e31f533b975ff10e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "max_input_length = 32\n",
    "max_target_length = 32\n",
    "source_lang = \"pl\"\n",
    "target_lang = \"mig\"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:58:31.531179527Z",
     "start_time": "2023-10-09T13:58:31.516012376Z"
    }
   },
   "id": "af1985d33eb3aac5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Map preprocess function on our dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aadcacc30862e00"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/92 [00:00<?, ? examples/s]/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3586: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = train_test_valid_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:58:35.149107516Z",
     "start_time": "2023-10-09T13:58:34.067592337Z"
    }
   },
   "id": "54bcc56f187af03b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py:388: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
    "train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "test_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_dataset[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:58:39.856545111Z",
     "start_time": "2023-10-09T13:58:39.402405388Z"
    }
   },
   "id": "5830af51b506f96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a217049eebb7099b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_marian_mt_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFMarianMainLayer)   multiple                  77138944  \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 63430     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,202,374\n",
      "Trainable params: 77,138,944\n",
      "Non-trainable params: 63,430\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:58:55.062697945Z",
     "start_time": "2023-10-09T13:58:54.996157088Z"
    }
   },
   "id": "6829cfa570b0b8c7"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'encoder',\n 'trainable': False,\n 'dtype': 'float32',\n 'config': {'vocab_size': 63430,\n  'decoder_vocab_size': 63430,\n  'max_position_embeddings': 512,\n  'd_model': 512,\n  'encoder_ffn_dim': 2048,\n  'encoder_layers': 6,\n  'encoder_attention_heads': 8,\n  'decoder_ffn_dim': 2048,\n  'decoder_layers': 6,\n  'decoder_attention_heads': 8,\n  'dropout': 0.1,\n  'attention_dropout': 0.0,\n  'activation_dropout': 0.0,\n  'activation_function': 'swish',\n  'init_std': 0.02,\n  'encoder_layerdrop': 0.0,\n  'decoder_layerdrop': 0.0,\n  'use_cache': True,\n  'num_hidden_layers': 6,\n  'scale_embedding': True,\n  'share_encoder_decoder_embeddings': True,\n  'return_dict': True,\n  'output_hidden_states': False,\n  'output_attentions': False,\n  'torchscript': False,\n  'torch_dtype': None,\n  'use_bfloat16': False,\n  'tf_legacy_loss': False,\n  'pruned_heads': {},\n  'tie_word_embeddings': True,\n  'is_encoder_decoder': True,\n  'is_decoder': False,\n  'cross_attention_hidden_size': None,\n  'add_cross_attention': False,\n  'tie_encoder_decoder': False,\n  'max_length': 512,\n  'min_length': 0,\n  'do_sample': False,\n  'early_stopping': False,\n  'num_beams': 6,\n  'num_beam_groups': 1,\n  'diversity_penalty': 0.0,\n  'temperature': 1.0,\n  'top_k': 50,\n  'top_p': 1.0,\n  'typical_p': 1.0,\n  'repetition_penalty': 1.0,\n  'length_penalty': 1.0,\n  'no_repeat_ngram_size': 0,\n  'encoder_no_repeat_ngram_size': 0,\n  'bad_words_ids': [[63429]],\n  'num_return_sequences': 1,\n  'chunk_size_feed_forward': 0,\n  'output_scores': False,\n  'return_dict_in_generate': False,\n  'forced_bos_token_id': None,\n  'forced_eos_token_id': 0,\n  'remove_invalid_values': False,\n  'exponential_decay_length_penalty': None,\n  'suppress_tokens': None,\n  'begin_suppress_tokens': None,\n  'architectures': ['MarianMTModel'],\n  'finetuning_task': None,\n  'id2label': {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'},\n  'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2},\n  'tokenizer_class': None,\n  'prefix': None,\n  'bos_token_id': 0,\n  'pad_token_id': 63429,\n  'eos_token_id': 0,\n  'sep_token_id': None,\n  'decoder_start_token_id': 63429,\n  'task_specific_params': None,\n  'problem_type': None,\n  '_name_or_path': './model/model.h5',\n  'transformers_version': '4.27.4',\n  '_num_labels': 3,\n  'add_bias_logits': False,\n  'add_final_layer_norm': False,\n  'classif_dropout': 0.0,\n  'classifier_dropout': 0.0,\n  'model_type': 'marian',\n  'normalize_before': False,\n  'normalize_embedding': False,\n  'static_position_embeddings': True}}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder.trainable = False\n",
    "model.model.encoder.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:58:57.604015352Z",
     "start_time": "2023-10-09T13:58:57.591941488Z"
    }
   },
   "id": "173df6be7f15399a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'decoder',\n 'trainable': True,\n 'dtype': 'float32',\n 'config': {'vocab_size': 63430,\n  'decoder_vocab_size': 63430,\n  'max_position_embeddings': 512,\n  'd_model': 512,\n  'encoder_ffn_dim': 2048,\n  'encoder_layers': 6,\n  'encoder_attention_heads': 8,\n  'decoder_ffn_dim': 2048,\n  'decoder_layers': 6,\n  'decoder_attention_heads': 8,\n  'dropout': 0.1,\n  'attention_dropout': 0.0,\n  'activation_dropout': 0.0,\n  'activation_function': 'swish',\n  'init_std': 0.02,\n  'encoder_layerdrop': 0.0,\n  'decoder_layerdrop': 0.0,\n  'use_cache': True,\n  'num_hidden_layers': 6,\n  'scale_embedding': True,\n  'share_encoder_decoder_embeddings': True,\n  'return_dict': True,\n  'output_hidden_states': False,\n  'output_attentions': False,\n  'torchscript': False,\n  'torch_dtype': None,\n  'use_bfloat16': False,\n  'tf_legacy_loss': False,\n  'pruned_heads': {},\n  'tie_word_embeddings': True,\n  'is_encoder_decoder': True,\n  'is_decoder': False,\n  'cross_attention_hidden_size': None,\n  'add_cross_attention': False,\n  'tie_encoder_decoder': False,\n  'max_length': 512,\n  'min_length': 0,\n  'do_sample': False,\n  'early_stopping': False,\n  'num_beams': 6,\n  'num_beam_groups': 1,\n  'diversity_penalty': 0.0,\n  'temperature': 1.0,\n  'top_k': 50,\n  'top_p': 1.0,\n  'typical_p': 1.0,\n  'repetition_penalty': 1.0,\n  'length_penalty': 1.0,\n  'no_repeat_ngram_size': 0,\n  'encoder_no_repeat_ngram_size': 0,\n  'bad_words_ids': [[63429]],\n  'num_return_sequences': 1,\n  'chunk_size_feed_forward': 0,\n  'output_scores': False,\n  'return_dict_in_generate': False,\n  'forced_bos_token_id': None,\n  'forced_eos_token_id': 0,\n  'remove_invalid_values': False,\n  'exponential_decay_length_penalty': None,\n  'suppress_tokens': None,\n  'begin_suppress_tokens': None,\n  'architectures': ['MarianMTModel'],\n  'finetuning_task': None,\n  'id2label': {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'},\n  'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2},\n  'tokenizer_class': None,\n  'prefix': None,\n  'bos_token_id': 0,\n  'pad_token_id': 63429,\n  'eos_token_id': 0,\n  'sep_token_id': None,\n  'decoder_start_token_id': 63429,\n  'task_specific_params': None,\n  'problem_type': None,\n  '_name_or_path': './model/model.h5',\n  'transformers_version': '4.27.4',\n  '_num_labels': 3,\n  'add_bias_logits': False,\n  'add_final_layer_norm': False,\n  'classif_dropout': 0.0,\n  'classifier_dropout': 0.0,\n  'model_type': 'marian',\n  'normalize_before': False,\n  'normalize_embedding': False,\n  'static_position_embeddings': True}}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.decoder.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:58:59.582147786Z",
     "start_time": "2023-10-09T13:58:59.530778586Z"
    }
   },
   "id": "b1a2535857070e09"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_marian_mt_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFMarianMainLayer)   multiple                  77138944  \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 63430     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,202,374\n",
      "Trainable params: 25,486,336\n",
      "Non-trainable params: 51,716,038\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:59:01.398488612Z",
     "start_time": "2023-10-09T13:59:01.335709187Z"
    }
   },
   "id": "3b0b3269120f6c69"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T13:59:04.635021152Z",
     "start_time": "2023-10-09T13:59:04.592687549Z"
    }
   },
   "id": "b6db2b883e135084"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize neptune"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4023074d4d0c994"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66/2714186411.py:1: NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-1\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"kacperurban/pl-mig-translation\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3MTRhNjcwNy1iMzc2LTQwNTUtOGRjYy03ODI4OGQzNjkxNTEifQ==\",\n",
    "    tags=[\"first-training\"],\n",
    ")\n",
    "\n",
    "neptune_callback = NeptuneCallback(run=run)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T14:03:24.526877347Z",
     "start_time": "2023-10-09T14:03:23.168006673Z"
    }
   },
   "id": "305f7ef50e6b3724"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cecfdc057fb1f1e"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 14:07:48.289529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [92]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-10-09 14:07:48.290403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [92]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-10-09 14:07:53.961721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice}}]]\n",
      "2023-10-09 14:07:53.961882: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice}}]]\n",
      "2023-10-09 14:07:54.006170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model/model/decoder/cond/add/tf_marian_mt_model/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model/model/decoder/cond/add/tf_marian_mt_model/model/decoder/strided_slice}}]]\n",
      "2023-10-09 14:08:05.443506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice}}]]\n",
      "2023-10-09 14:08:05.443605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model/model/decoder/cond/ones/packed/tf_marian_mt_model/model/decoder/strided_slice}}]]\n",
      "2023-10-09 14:08:05.483002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tf_marian_mt_model/model/decoder/cond/add/tf_marian_mt_model/model/decoder/strided_slice' with dtype int32\n",
      "\t [[{{node tf_marian_mt_model/model/decoder/cond/add/tf_marian_mt_model/model/decoder/strided_slice}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 41s 806ms/step - loss: 18.9141 - accuracy: 0.0308\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 8s 767ms/step - loss: 11.9886 - accuracy: 0.0191\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 9s 809ms/step - loss: 8.7155 - accuracy: 0.0100\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 9s 772ms/step - loss: 7.0207 - accuracy: 0.0289\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 9s 826ms/step - loss: 6.0778 - accuracy: 0.0240\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 9s 856ms/step - loss: 5.5677 - accuracy: 0.0291\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 9s 838ms/step - loss: 5.3249 - accuracy: 0.0287\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 11s 1s/step - loss: 5.1777 - accuracy: 0.0298\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 10s 895ms/step - loss: 5.0306 - accuracy: 0.0404\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 9s 825ms/step - loss: 4.9086 - accuracy: 0.0393\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 3 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 3 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/kacperurban/pl-mig-translation/e/PLMIG-1/metadata\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "model.fit(train_dataset, epochs=10, callbacks=[neptune_callback, early_stopping_callback])\n",
    "run.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T14:09:53.617578213Z",
     "start_time": "2023-10-09T14:07:48.259433641Z"
    }
   },
   "id": "890aff221066d41d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce767aa83db3c230"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
